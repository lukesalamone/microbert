# Micro BERT
Micro BERT is a project which aims to develop an encoder capable of computing embeddings for semantic similarity search, with the added constraint that the encoder must be under 10MB in size.

## Motivation

One of the major challenges in natural language processing is the ability to accurately compute semantic similarity between texts. However, many existing methods for computing semantic similarity rely on large, pre-trained language models, which can be impractical for certain use cases due to their size and computational requirements. Micro BERT aims to address this problem by developing an encoder that is both effective at computing semantic similarity and small enough to be used in resource-constrained environments.
